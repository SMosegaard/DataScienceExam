# Exam: Data Science, Prediction, and Forecasting

This repository contains the code for my exam project in the course "Data Science, Prediction, and Forecasting" as a part of my Master in Cognitive Science.

## 🔧 Setup and installation guide

Follow these steps to set up the project:

### 1.  Clone the repository
Start by cloning the repository to your local machine using the following command:
```python
$ git clone "https://github.com/SMosegaard/DataScienceExam.git"
```
### 2. Set up the virtual environment
Run the ```setup.sh``` script to create a virtual environment and install all required dependencies specified in ```requirements.txt```:
```python
$ source setup.sh
``` 
You are now working within the virtual environment!

Next, navigate into the ```scr/``` folder and execute the bash script for the Lag-Llama model, that will clone the Lag-Llama repo inside the folder:

```python
$ cd src
$ source lagllama_setup.sh
```

## 👩‍💻 Usage
Once the project has been set up, you can tune the hyperparameters for each model and test their performance. To do so, use the following commands and specify which model (--model / -m) to evaluate. There are currently three models available models: ARIMA, SVR, and Lag-Llama. Model names are not case-sensitive, so whether you type the options with capital letters or not will not affect the executions of the scripts.

```python
$ python tune.py -m {arima/svr/lagllama}
```
```python
$ python test.py -m {arima/svr/lagllama}
```
Please note, that the testing should only be performed after tuning, as ```test.py``` rely on optimized hyperparameters.

Based on the user input, the model will be tuned and tested on two datasets and two horizon lengths.

All outputs generated during tuning and testing is saved in the ```out/``` folder. The tuned hyperparameters are stored as files named ```{model}_hyperparameters.csv```, while the forecasting results are saved as ```{model}_{horizon}_{dataset}.csv```. Summaries of the evaluation metrics are also produced and saved as ```{model}_results.csv```

## 📈 Results

Finally, you can calculate the aggregated evaluation metrics and generate plots comparing the actual verus forecasted time series. To perform this step, simply run the following command:
```python
$ python results.py
```
The metrics summaries will be saved in the  ```out/``` folder as ```{model}_results_agg.csv```. Similarly, the generated visualizations will be saved in the ```plots/``` folder with filenames ```actual_vs_forecast_{dataset}_{horizon}.png```.

When finished, you can deactivate the virtual environment:
```python
$ deactivate
```

## 📂 Repository Overview
The project is structured to support a full forecasting workflow, including data prepreations, model tuning, evaluation, and visualization. Here is a breakdown of the project structure:

```
.
├── data/                          # Contains the datasets and a notebook for data visualisations
    ├── train                      # Training data
    ├── test                       # Testing data
    └── data_visualisations.ipynb  # Notebook for visualizing the data
├── out/                           # Stores output .csv files with tuned hyperparameters, forecast results, and metrics summaries  
├── plots/                         # Contains plots generated by the scripts in the src/ folder and the data notebook
├── src/                           # Source code for modeling and utilies
    ├── lagllama_setup.sh          # Script for setting up the the Lag-Llama environment
    ├── utils.py                   # General-purpose helper functions
    ├── arima_utils.py             # Functions specific to ARIMA modeling
    ├── svr_utils.py               # Functions specific to SVR modeling
    ├── lagllama_utils.py          # Functions specific to Lag-Llama modeling
    ├── tune.py                    # Script for hyperparameter tuning across models
    ├── test.py                    # Script for testing and evaluating model performance
    └── results.py                 # Script for aggregating the retuls and plotting the forecasts
├── .gitignore 
├── README.md
├── requirements.txt               # Project dependencies
└── setup.sh                       # Script for setting up the project environment
```


## References
For transparency, the hyperparameter tuning strategies are adapted from the following tutorials:
- [Lag-Llama tutorial](https://www.ibm.com/think/tutorials/lag-llama)
- [SVR tutorial 1](https://www.geeksforgeeks.org/time-series-forecasting-with-support-vector-regression/), [SVR tutorial 2](https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/)
