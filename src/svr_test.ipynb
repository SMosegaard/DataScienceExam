{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1e5a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52973d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_forecast_helper(model, last_window, horizon):\n",
    "    predictions = []\n",
    "    input_sequence = last_window.copy()\n",
    "\n",
    "    for _ in range(horizon):\n",
    "        input_array = np.array(input_sequence[-len(last_window):]).reshape(1, -1)\n",
    "        next_prediction = model.predict(input_array)[0]\n",
    "        predictions.append(next_prediction)\n",
    "        input_sequence.append(next_prediction)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "843facb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from arima utils\n",
    "\n",
    "def rolling_origin_eval_prep(df_train, df_test, horizon):\n",
    "    train_split, test_split = [], [] # initialize empty lists to store each train and test split\n",
    "    for i in range(0, len(df_test) - horizon + 1):\n",
    "        curr_train = pd.concat([df_train, df_test.iloc[:i]], axis = 0)\n",
    "        curr_test = df_test.iloc[i:i + horizon] # create a test windos from i to i+horizon, meaning select the next \"horizon step\" of test data starting from i\n",
    "        train_split.append(curr_train)\n",
    "        test_split.append(curr_test)\n",
    "    return train_split, test_split\n",
    "\n",
    "def cal_smape(actual, forecast):\n",
    "    actual, forecast = np.array(actual), np.array(forecast) # convert actual and forecasted values to numpy arrays\n",
    "    denominator = (np.abs(actual) + np.abs(forecast)) / 2\n",
    "    difference = np.abs(actual - forecast) / denominator\n",
    "    difference = np.where(denominator == 0, 0, difference) # to avoid dividing by 0 or NaN\n",
    "    return 100 * np.mean(difference)\n",
    "\n",
    "\n",
    "def evaluate(actual, forecast):\n",
    "    mae = round(mean_absolute_error(actual, forecast), 3)\n",
    "    mse = round(mean_squared_error(actual, forecast), 3)\n",
    "    rmse = round(np.sqrt(mse), 3)\n",
    "    smape = round(cal_smape(actual, forecast), 3)\n",
    "    return mae, mse, rmse, smape\n",
    "\n",
    "\n",
    "def data_prep(test, dataset):\n",
    "    df_train = pd.read_csv(f\"../data/train/{dataset}_train.csv\")\n",
    "    df_test = pd.read_csv(f\"../data/test/{dataset}_test_{test}.csv\")\n",
    "\n",
    "    if dataset == \"weather\":\n",
    "        df_train.rename(columns = {\"date\": \"date\", \"temperature\": \"y\"}, inplace = True)\n",
    "        df_test.rename(columns = {\"date\": \"date\", \"temperature\": \"y\"}, inplace = True)\n",
    "\n",
    "    if dataset == \"carbon\":\n",
    "        df_train.rename(columns = {\"date\": \"date\", \"carbon_intensity\": \"y\"}, inplace = True)\n",
    "        df_test.rename(columns = {\"date\": \"date\", \"carbon_intensity\": \"y\"}, inplace = True)\n",
    "\n",
    "    return df_train, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf6bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_label = [\"weather\", \"carbon\"]\n",
    "test_size_label = [\"small\", \"large\"]\n",
    "horizons = [5, 50]\n",
    "all_metrics = []\n",
    "\n",
    "\n",
    "for dataset in dataset_label:\n",
    "    for horizon in horizons:\n",
    "        if horizon == 5:\n",
    "            test_size = \"small\"\n",
    "        elif horizon == 50:\n",
    "            test_size = \"large\"\n",
    "        \n",
    "        print(f\"Testing!\\n\")\n",
    "        print(f\"{dataset} dataset: running horizon {horizon} (test size {test_size})\\n\")\n",
    "\n",
    "        df_train, df_test = data_prep(test_size, dataset)\n",
    "        train_split, test_split = rolling_origin_eval_prep(df_train, df_test, horizon)\n",
    "\n",
    "        forecast_df = pd.DataFrame()\n",
    "        forecast_df[\"date\"] = df_test.index\n",
    "        forecast_df[\"y\"] = df_test[\"y\"].values\n",
    "\n",
    "        window_size = 3\n",
    "\n",
    "        for i, (curr_train, curr_test) in enumerate(zip(train_split, test_split)):\n",
    "\n",
    "            y_train = curr_train[\"y\"].values\n",
    "\n",
    "            # Creating the sliding window training data\n",
    "            X_train, y_target = [], []\n",
    "            for j in range(len(y_train) - window_size):\n",
    "                X_train.append(y_train[j:j + window_size])\n",
    "                y_target.append(y_train[j + window_size])\n",
    "            \n",
    "            model = SVR()\n",
    "            model.fit(X_train, y_target)\n",
    "\n",
    "            last_window = list(y_train[-window_size:])\n",
    "            forecast = svr_forecast_helper(model, last_window, horizon)\n",
    "\n",
    "            actual = curr_test[\"y\"].values\n",
    "\n",
    "            i_forecast = np.concatenate([np.repeat(np.nan, i), forecast, np.repeat(np.nan, len(df_test) - i - horizon)])\n",
    "            forecast_df[f\"{i}\"] = i_forecast\n",
    "\n",
    "            mae, mse, rmse, smape = evaluate(actual, forecast)\n",
    "\n",
    "            metadata_dict = {\"dataset\": dataset,\n",
    "                        \"test_size\": test_size,\n",
    "                        \"horizon\": horizon,\n",
    "                        \"iter\": i,\n",
    "                        \"mae\": round(mae),\n",
    "                        \"mse\": round(mse),\n",
    "                        \"rmse\": round(rmse),\n",
    "                        \"smape\": round(smape)}\n",
    "            \n",
    "            forecast_df.to_csv(f\"../out/svr_{horizon}_{dataset}.csv\", index = False)\n",
    "            all_metrics.append(metadata_dict)\n",
    "\n",
    "    metrics_df = pd.DataFrame(all_metrics)\n",
    "    metrics_df.to_csv(f\"../out/svr_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be29a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that I calculate sMAPE correctly... might not, because I got 146 value. itr 3. weather, 5 h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b4f5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b964b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "\n",
    "# params? kernel, gamme, C, epsilon, windows size\n",
    "# model = SVR(kernel='rbf', gamma=0.5, C=10, epsilon=0.05)\n",
    "\n",
    "param_dict = {\"C\": [0.1, 1, 10, 100],\n",
    "                \"epsilon\": [0.01, 0.1, 0.5],\n",
    "                \"gamma\": [\"scale\", \"auto\", 0.1, 0.5]}\n",
    "windows = [5, 10, 24] #?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f78fe03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ca8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "grid_search = GridSearchCV(estimator = svr, param_grid = param_dict, verbose = 2, n_jobs = -1)\n",
    "\n",
    "grid_search.fit(...)\n",
    "best_csv = grid_search.best_estimator_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
